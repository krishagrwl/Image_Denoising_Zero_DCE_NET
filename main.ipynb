{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1HFE2AhsJ-vzFov2k4aorxsIJ5LHISjwB","authorship_tag":"ABX9TyM0WKrPzNDJD35cVcjsgNU8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"v4NKFTGqVFi0","executionInfo":{"status":"ok","timestamp":1718724877724,"user_tz":-330,"elapsed":5385,"user":{"displayName":"HARDIK AGARWAL 22115060","userId":"09117271253273185878"}}},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","from glob import glob\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers,Input,Model\n","\n"]},{"cell_type":"code","source":["# for running this code zero_dce_model should be in same directory\n","cur_path = os.getcwd()\n","sys.path.append('/content/drive/MyDrive/image_denoising')\n","from zero_dce_model import ZeroDCE  # if this doesn't work I have mentioned the model in next cell\n","\n","# Create the model architecture\n","os.chdir('/content/drive/MyDrive/image_denoising')   #(used to shift to current directory while checking the code)"],"metadata":{"id":"uED-yBF-aOKu","executionInfo":{"status":"ok","timestamp":1718724895135,"user_tz":-330,"elapsed":1184,"user":{"displayName":"HARDIK AGARWAL 22115060","userId":"09117271253273185878"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#run if above cell doesn't work\n","def build_dce():\n","    input_img = keras.Input(shape=[None, None, 3])\n","    conv1 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(input_img)\n","    conv2 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(conv1)\n","    conv3 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(conv2)\n","    conv4 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(conv3)\n","    int_con1 = layers.Concatenate(axis=-1)([conv4, conv3])\n","    conv5 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(int_con1)\n","    int_con2 = layers.Concatenate(axis=-1)([conv5, conv2])\n","    conv6 = layers.Conv2D(\n","        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n","    )(int_con2)\n","    int_con3 = layers.Concatenate(axis=-1)([conv6, conv1])\n","    x_r = layers.Conv2D(24, (3, 3), strides=(1, 1), activation=\"tanh\", padding=\"same\")(\n","        int_con3\n","    )\n","    return keras.Model(inputs=input_img, outputs=x_r)\n","def illumination_smoothness_loss(x):\n","    batch_size = tf.shape(x)[0]\n","    height_x = tf.shape(x)[1]\n","    width_x = tf.shape(x)[2]\n","    count_h = (tf.shape(x)[2] - 1) * tf.shape(x)[3]\n","    count_w = tf.shape(x)[2] * (tf.shape(x)[3] - 1)\n","    h_tv = tf.reduce_sum(tf.square((x[:, 1:, :, :] - x[:, : height_x - 1, :, :])))\n","    w_tv = tf.reduce_sum(tf.square((x[:, :, 1:, :] - x[:, :, : width_x - 1, :])))\n","    batch_size = tf.cast(batch_size, dtype=tf.float32)\n","    count_h = tf.cast(count_h, dtype=tf.float32)\n","    count_w = tf.cast(count_w, dtype=tf.float32)\n","    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n","def exposure_control_loss(x, mean_val=0.6):    #after experimentation we took mean_val (E=0.6)\n","    x = tf.reduce_mean(x, axis=3, keepdims=True)\n","    mean = tf.nn.avg_pool2d(x, ksize=16, strides=16, padding=\"VALID\")\n","    return tf.reduce_mean(tf.square(mean - mean_val))\n","def color_constancy_loss(x):\n","    mean_rgb = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n","    mean_r, mean_g, mean_b = mean_rgb[:, :, :, 0], mean_rgb[:, :, :, 1], mean_rgb[:, :, :, 2]\n","    diff_rg = tf.square(mean_r - mean_g)\n","    diff_rb = tf.square(mean_r - mean_b)\n","    diff_gb = tf.square(mean_b - mean_g)\n","    return tf.sqrt(tf.square(diff_rg) + tf.square(diff_rb) + tf.square(diff_gb))\n","class SpatialConsistencyLoss(keras.losses.Loss):\n","    def __init__(self, **kwargs):\n","        super(SpatialConsistencyLoss, self).__init__(reduction=\"none\")\n","\n","        self.left_kernel = tf.constant(\n","            [[[[0, 0, 0]], [[-1, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n","        )\n","        self.right_kernel = tf.constant(\n","            [[[[0, 0, 0]], [[0, 1, -1]], [[0, 0, 0]]]], dtype=tf.float32\n","        )\n","        self.up_kernel = tf.constant(\n","            [[[[0, -1, 0]], [[0, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n","        )\n","        self.down_kernel = tf.constant(\n","            [[[[0, 0, 0]], [[0, 1, 0]], [[0, -1, 0]]]], dtype=tf.float32\n","        )\n","\n","    def call(self, y_true, y_pred):\n","\n","        original_mean = tf.reduce_mean(y_true, 3, keepdims=True)\n","        enhanced_mean = tf.reduce_mean(y_pred, 3, keepdims=True)\n","        original_pool = tf.nn.avg_pool2d(\n","            original_mean, ksize=4, strides=4, padding=\"VALID\"\n","        )\n","        enhanced_pool = tf.nn.avg_pool2d(\n","            enhanced_mean, ksize=4, strides=4, padding=\"VALID\"\n","        )\n","\n","        d_original_left = tf.nn.conv2d(\n","            original_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_original_right = tf.nn.conv2d(\n","            original_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_original_up = tf.nn.conv2d(\n","            original_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_original_down = tf.nn.conv2d(\n","            original_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","\n","        d_enhanced_left = tf.nn.conv2d(\n","            enhanced_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_enhanced_right = tf.nn.conv2d(\n","            enhanced_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_enhanced_up = tf.nn.conv2d(\n","            enhanced_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","        d_enhanced_down = tf.nn.conv2d(\n","            enhanced_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n","        )\n","\n","        d_left = tf.square(d_original_left - d_enhanced_left)\n","        d_right = tf.square(d_original_right - d_enhanced_right)\n","        d_up = tf.square(d_original_up - d_enhanced_up)\n","        d_down = tf.square(d_original_down - d_enhanced_down)\n","        return d_left + d_right + d_up + d_down\n","\n","\n","class ZeroDCE(keras.Model):\n","    def __init__(self, **kwargs):\n","        super(ZeroDCE, self).__init__(**kwargs)\n","        self.dce_model = build_dce()\n","\n","    def compile(self, learning_rate, **kwargs):\n","        super(ZeroDCE, self).compile(**kwargs)\n","        self.optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n","        self.spatial_constancy_loss = SpatialConsistencyLoss(reduction=\"none\")\n","\n","    def get_enhanced_image(self, data, output):\n","        r1 = output[:, :, :, :3]\n","        r2 = output[:, :, :, 3:6]\n","        r3 = output[:, :, :, 6:9]\n","        r4 = output[:, :, :, 9:12]\n","        r5 = output[:, :, :, 12:15]\n","        r6 = output[:, :, :, 15:18]\n","        r7 = output[:, :, :, 18:21]\n","        r8 = output[:, :, :, 21:24]\n","        x = data + r1 * (tf.square(data) - data)\n","        x = x + r2 * (tf.square(x) - x)\n","        x = x + r3 * (tf.square(x) - x)\n","        enhanced_image = x + r4 * (tf.square(x) - x)\n","        x = enhanced_image + r5 * (tf.square(enhanced_image) - enhanced_image)\n","        x = x + r6 * (tf.square(x) - x)\n","        x = x + r7 * (tf.square(x) - x)\n","        enhanced_image = x + r8 * (tf.square(x) - x)\n","        return enhanced_image\n","\n","    def call(self, data):\n","        dce_net_output = self.dce_model(data)\n","        return self.get_enhanced_image(data, dce_net_output)\n","\n","    def compute_losses(self, data, output):\n","        enhanced_image = self.get_enhanced_image(data, output)\n","        loss_illumination = 200 * illumination_smoothness_loss(output)\n","        loss_spatial_constancy = tf.reduce_mean(\n","            self.spatial_constancy_loss(enhanced_image, data)\n","        )\n","        loss_color_constancy = 5 * tf.reduce_mean(color_constancy_loss(enhanced_image))\n","        loss_exposure = 10 * tf.reduce_mean(exposure_control_loss(enhanced_image))\n","        total_loss = (\n","            loss_illumination\n","            + loss_spatial_constancy\n","            + loss_color_constancy\n","            + loss_exposure\n","        )\n","        return {\n","            \"total_loss\": total_loss,\n","            \"illumination_smoothness_loss\": loss_illumination,\n","            \"spatial_constancy_loss\": loss_spatial_constancy,\n","            \"color_constancy_loss\": loss_color_constancy,\n","            \"exposure_loss\": loss_exposure,\n","        }\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            output = self.dce_model(data)\n","            losses = self.compute_losses(data, output)\n","        gradients = tape.gradient(\n","            losses[\"total_loss\"], self.dce_model.trainable_weights\n","        )\n","        self.optimizer.apply_gradients(zip(gradients, self.dce_model.trainable_weights))\n","        return losses\n","\n","    def test_step(self, data):\n","        output = self.dce_model(data)\n","        return self.compute_losses(data, output)\n","\n","    def save_weights(self, filepath, overwrite=True, save_format=None, options=None):\n","        \"\"\"While saving the weights, we simply save the weights of the DCE-Net\"\"\"\n","        self.dce_model.save_weights(\n","            filepath, overwrite=overwrite, save_format=save_format, options=options\n","        )\n","\n","    def load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None):\n","        \"\"\"While loading the weights, we simply load the weights of the DCE-Net\"\"\"\n","        self.dce_model.load_weights(\n","            filepath=filepath,\n","            by_name=by_name,\n","            skip_mismatch=skip_mismatch,\n","            options=options,\n","        )\n"],"metadata":{"id":"6tuoPPtvbwo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ZeroDCE()\n","\n","# Compile the model with the optimizer and learning rate\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),learning_rate=1e-4)\n","\n","# Load the model weights\n","current_directory = os.getcwd()\n","\n","save_weight = 'model1.h5'\n","model_path = os.path.join(current_directory,save_weight)\n","\n","\n"],"metadata":{"id":"peyCBAmDVyvL","executionInfo":{"status":"ok","timestamp":1718725071227,"user_tz":-330,"elapsed":521,"user":{"displayName":"HARDIK AGARWAL 22115060","userId":"09117271253273185878"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model.load_weights(model_path)\n","\n","def infer(original_image):\n","    image = keras.preprocessing.image.img_to_array(original_image)\n","    # Scaling as done during model training\n","    image = image.astype(\"float32\") / 255.0\n","    image = np.expand_dims(image, axis=0)\n","    output_image = model(image)\n","    output_image = tf.cast((output_image[0, :, :, :] * 255), dtype=np.uint8)\n","    output_image = Image.fromarray(output_image.numpy())\n","    return output_image\n","\n","# Use glob to get the list of test images\n","test_images = sorted(glob(r'./test/low/*'))\n","save_dir = r'test/predicted'\n","\n","path = os.path.join(current_directory,save_dir)\n","# Ensure the save directory exists\n","if not os.path.exists(path):\n","    # print(path)\n","    os.makedirs(path)\n","\n","for val_image_file in test_images:\n","    original_image = Image.open(val_image_file)\n","\n","    enhanced_image = infer(original_image)\n","\n","    original_image_np = np.array(original_image)\n","    enhanced_image_np = np.array(enhanced_image)\n","\n","    file_name = os.path.basename(val_image_file)\n","    output_path = os.path.join(path, 'enhanced_' + file_name)\n","    enhanced_image.save(output_path)\n","\n","    plt.imshow(enhanced_image)\n","    plt.axis('off')\n","    plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1kSj17mf1kANkooXDZTjw1qZdHsGIKuRh"},"id":"7tci3CmD_fKm","executionInfo":{"status":"ok","timestamp":1718725115060,"user_tz":-330,"elapsed":37380,"user":{"displayName":"HARDIK AGARWAL 22115060","userId":"09117271253273185878"}},"outputId":"4bee395d-c02e-4f0c-da2d-36b7f8e563f4"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["print(output_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRdyd1YJWNQQ","executionInfo":{"status":"ok","timestamp":1718715363546,"user_tz":-330,"elapsed":449,"user":{"displayName":"HARDIK AGARWAL 22115060","userId":"09117271253273185878"}},"outputId":"c1c4c903-7f69-4add-cba5-a37e8759cb57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/image_denoising/test/predicted/enhanced_79.png\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Fp5OVcZMW4A-"},"execution_count":null,"outputs":[]}]}